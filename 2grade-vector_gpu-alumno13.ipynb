{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3431319e-2e6b-43c1-a2f6-61ccba592c21",
   "metadata": {},
   "source": [
    "## Evaluating a vectorial function on CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d142183-b6bb-42e7-ba9d-35bf0f91dc0c",
   "metadata": {},
   "source": [
    "### CPU: plain and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92dd336-9997-4323-80e4-f285e9cc2db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "8.44 ms ± 97 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.4 ms ± 34.3 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.4 ms ± 27 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "\n",
    "# Python plain implementation w/ numba \n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a*x[i]*x[i] + b*y[i] + c\n",
    "    return z\n",
    "\n",
    "# Numpy ufunc\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# size of the vectors\n",
    "size = 5_000_000\n",
    "\n",
    "# allocating and populating the vectors\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "c_cpu = np.zeros(size)\n",
    "\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10\n",
    "\n",
    "# Printing input values\n",
    "#print(a_cpu)\n",
    "#print(b_cpu)\n",
    "# Random function in Numpy always use float64\n",
    "print(a_cpu.dtype)\n",
    "\n",
    "c_cpu = grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "\n",
    "# Evaluating the time\n",
    "\n",
    "# Numba Python: huge improvement, better that numpy code\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# w/ a numpy ufunc manually coded\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# using the general numpy ufunc \n",
    "%timeit -n 5 -r 2 a*a_cpu**2 + b*b_cpu + c\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d4b07-0ab6-478a-a5b7-842889175ce8",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2 apartado A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a462ebeb-5712-4645-a289-402e631eafab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Resultado benchmark CuPy (con copia):\n",
      "  Tiempo: 21.074 ms\n",
      "Resultado benchmark CuPy (sin copia):\n",
      "  Tiempo: 5.542 ms\n",
      "Resultados de numba y numpy:\n",
      "8.32 ms ± 9.57 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.7 ms ± 43.5 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.6 ms ± 63.7 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "import cupy as cp\n",
    "from cupyx.profiler import benchmark\n",
    "# Python plain implementation w/ numba \n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a*x[i]*x[i] + b*y[i] + c\n",
    "    return z\n",
    "\n",
    "# Numpy ufunc\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# size of the vectors\n",
    "size = 5_000_000\n",
    "\n",
    "# allocating and populating the vectors\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "c_cpu = np.zeros(size)\n",
    "\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10\n",
    "\n",
    "# Printing input values\n",
    "#print(a_cpu)\n",
    "#print(b_cpu)\n",
    "# Random function in Numpy always use float64\n",
    "print(a_cpu.dtype)\n",
    "\n",
    "def cupy_copia():\n",
    "    # Copiar arrays de CPU a GPU\n",
    "    a_gpu = cp.asarray(a_cpu)\n",
    "    b_gpu = cp.asarray(b_cpu)\n",
    "    \n",
    "    # Calcular en GPU (usando ufunc de CuPy)\n",
    "    result_gpu = a * a_gpu**2 + b * b_gpu + c\n",
    "    \n",
    "    # Copiar resultado de vuelta a CPU\n",
    "    return cp.asnumpy(result_gpu)\n",
    "\n",
    "# Medir tiempo con la función benchmark de CuPy\n",
    "cp_benchmark = benchmark(cupy_copia, n_repeat=5, n_warmup=2)\n",
    "c_cpu = grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "gpu_avg_time = np.average(cp_benchmark.gpu_times) * 1e3\n",
    "print(f\"Resultado benchmark CuPy (con copia):\")\n",
    "print(f\"  Tiempo: {gpu_avg_time:.3f} ms\")\n",
    "\n",
    "\n",
    "def cupy_sin_copia():\n",
    "    # Crear arrays directamente en GPU (equivalente a np.random.rand)\n",
    "    a_gpu = cp.random.rand(size)\n",
    "    b_gpu = cp.random.rand(size)\n",
    "    \n",
    "    # Calcular en GPU\n",
    "    result_gpu = a * a_gpu**2 + b * b_gpu + c\n",
    "    \n",
    "    # Devolver resultado en GPU (sin copiar a CPU)\n",
    "    return result_gpu\n",
    "\n",
    "# Medir tiempo con benchmark de CuPy\n",
    "cp_benchmark_sincopia = benchmark(cupy_sin_copia, n_repeat=5, n_warmup=2)\n",
    "gpu_avg_time = np.average(cp_benchmark_sincopia.gpu_times) * 1e3\n",
    "print(f\"Resultado benchmark CuPy (sin copia):\")\n",
    "print(f\"  Tiempo: {gpu_avg_time:.3f} ms\")\n",
    "# Evaluating the time\n",
    "print(\"Resultados de numba y numpy:\")\n",
    "# Numba Python: huge improvement, better that numpy code\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# w/ a numpy ufunc manually coded\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# using the general numpy ufunc \n",
    "%timeit -n 5 -r 2 a*a_cpu**2 + b*b_cpu + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b03a385-da2e-4ff1-804a-a05cdf491234",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2 apartado B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9f02e6-9789-4e1b-95f5-e5fa947696f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Tiempo promedio: 31.058 ms\n",
      "Tiempo kernel CUDA: 8.017 ms\n",
      "Resultados de numba y numpy:\n",
      "The slowest run took 7.21 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "31.8 ms ± 24 ms per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.6 ms ± 96.2 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "18.5 ms ± 64 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, jit, vectorize, cuda\n",
    "import cupy as cp\n",
    "from cupyx.profiler import benchmark\n",
    "import time\n",
    "# Python plain implementation w/ numba \n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a*x[i]*x[i] + b*y[i] + c\n",
    "    return z\n",
    "\n",
    "# Numpy ufunc\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# size of the vectors\n",
    "size = 5_000_000\n",
    "\n",
    "# allocating and populating the vectors\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "c_cpu = np.zeros(size)\n",
    "\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10\n",
    "\n",
    "@vectorize(['float64(float64, float64, float64, float64, float64)'], target='cuda')  \n",
    "def grade2_numba_gpu_elementwise(x, y, a, b, c):\n",
    "    return a*x*x + b*y + c\n",
    "# Printing input values\n",
    "#print(a_cpu)\n",
    "#print(b_cpu)\n",
    "# Random function in Numpy always use float64\n",
    "print(a_cpu.dtype)\n",
    "\n",
    "# Función para medir incluyendo la copia\n",
    "def numba_gpu_copia():\n",
    "    # La copia ocurre automáticamente dentro de la función ufunc\n",
    "    return grade2_numba_gpu_elementwise(a_cpu, b_cpu, a, b, c)\n",
    "times = []\n",
    "for i in range(5):\n",
    "    start = time.perf_counter()\n",
    "    result = numba_gpu_copia()\n",
    "    end = time.perf_counter()\n",
    "    times.append((end - start) * 1000)  # Convertir a ms\n",
    "\n",
    "print(f\"Tiempo promedio: {np.mean(times):.3f} ms\")\n",
    "\n",
    "\n",
    "# Crear arrays en GPU\n",
    "a_gpu = cuda.to_device(a_cpu)\n",
    "b_gpu = cuda.to_device(b_cpu)\n",
    "# Crear array de salida en GPU\n",
    "result_gpu = cuda.device_array_like(a_cpu)\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def grade2_cuda_kernel(x, y, a, b, c, out):\n",
    "    i = cuda.grid(1)\n",
    "    if i < x.size:\n",
    "        out[i] = a * x[i] * x[i] + b * y[i] + c\n",
    "\n",
    "threads_per_block = 256\n",
    "blocks_per_grid = (size + (threads_per_block - 1)) // threads_per_block\n",
    "\n",
    "times_kernel = []\n",
    "for _ in range(5):\n",
    "    start = time.perf_counter()\n",
    "    grade2_cuda_kernel[blocks_per_grid, threads_per_block](a_gpu, b_gpu, a, b, c, result_gpu)\n",
    "    cuda.synchronize()  # Esperar a que termine la GPU\n",
    "    end = time.perf_counter()\n",
    "    times_kernel.append((end - start) * 1000)\n",
    "\n",
    "print(f\"Tiempo CUDA sin copia: {np.mean(times_kernel):.3f} ms\")\n",
    "# Evaluating the time\n",
    "print(\"Resultados de numba y numpy:\")\n",
    "# Numba Python: huge improvement, better that numpy code\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# w/ a numpy ufunc manually coded\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# using the general numpy ufunc \n",
    "%timeit -n 5 -r 2 a*a_cpu**2 + b*b_cpu + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce00ad67-60a5-4fd1-843d-3a30e665c717",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2 apartado C\n",
    "Al realizar ambos apartados vemos que en ambos casos la ejecucion sin copia es mas rapida que la que copia de cpu a gpu para realizar la operacion; pero la opcion mas rapida es cupy sobre numba Cuda. Siendo en numba cuda de 8 ms y en cupy 5.5ms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
